{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Pandas and Numpy: 2 Dimensional Data\n",
    "\n",
    "Both Numpy and Pandas offer data structures that you can use to work with 2 Dimensional data organized into rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Numpy 2D Arrays\n",
    "\n",
    "Numpy offers the 2D Array data structure to store 2 dimensional data. In python you would store 2D data as a list of lists, however Numpy offers 2D Arrays to store such data. This is more memory efficient than a list of lists. Data is accessed using the row and column index `array[<row>, <col>]`. You can also use the slice operator to calculate ranges of data `array[1, :]` (second row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  4]\n",
      " [ 6  7  8]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# Subway ridership for 5 stations on 10 different days\n",
    "ridership = np.array([\n",
    "    [0, 0, 2, 5, 0],\n",
    "    [1478, 3877, 3674, 2328, 2539],\n",
    "    [1613, 4088, 3991, 6461, 2691],\n",
    "    [1560, 3392, 3826, 4787, 2613],\n",
    "    [1608, 4802, 3932, 4477, 2705],\n",
    "    [1576, 3933, 3909, 4979, 2685],\n",
    "    [95, 229, 255, 496, 201],\n",
    "    [2, 0, 1, 27, 0],\n",
    "    [1438, 3785, 3589, 4174, 2215],\n",
    "    [1342, 4043, 4009, 4665, 3033]\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print(ridership[1, 3])\n",
    "    print(ridership[1:3, 3:5])\n",
    "    print(ridership[1, :])\n",
    "\n",
    "# Vectorized operations on rows or columns\n",
    "if False:\n",
    "    print(ridership[0, :] + ridership[1, :])\n",
    "    print(ridership[:, 0] + ridership[:, 1])\n",
    "\n",
    "# Vectorized operations on entire arrays\n",
    "if True:\n",
    "    a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "    b = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "    print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise\n",
    "Write a function that, given a 2D array of subway stations and ridership, calculates the mean ridership for the station with the most number of riders in the first day and the overall ridership mean on the entire data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. Also\n",
    "    return the mean ridership overall for comparsion.\n",
    "\n",
    "    Hint: NumPy's argmax() function might be useful:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.argmax.html\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "mean_riders_for_max_station(ridership)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Numpy Axis\n",
    "\n",
    "Numpy array operations take in an `axis` operation that specifies the axis (row or column) along which the operation should be performed.\n",
    "\n",
    "As an example, for the ridership array in the previous example, in order to calculate the mean ridership for each station you would pass `axis=0` (column-wise) to the mean function. Similarly to calculate the mean ridership for each date (row-wise) you would pass `axis=1`\n",
    "\n",
    "```python\n",
    "mean_rides_per_station = ridership.mean(axis=0)\n",
    "mean_rides_per_day = ridership.mean(axis=1)\n",
    "```\n",
    "\n",
    "### Limitations\n",
    "Numpy 2-D Arrays are not designed to handle data where with the columns are of different data types. For the case where you have a 2D Numpy array with a column of ints, a column of Strings and a column of Dates, all of the data will be converted to the String data type, and math operations like `mean()` will not work as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Pandas DataFrames\n",
    "\n",
    "A DataFrame is a data structure from the Pandas library that is used to hold 2-Dimensional data. Like Series and 1-D Numpy arrays, Pandas DataFrames offer the same operations that a 2-D Numpy array does, but DataFrames are much more powerful due to the additional operations that they offer. \n",
    "\n",
    "A DataFrame is a collection of Pandas Series where each Series represents a column of data in the dataframe and can be assumed to be of a different data type. Thus a DataFrame does not have the limitation of requring all columns to be of the same data type, and a DataFrame applies math operations only to the numerical series contained within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_key        3.0\n",
      "days_to_cancel    12.8\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({\n",
    "    'account_key': [1, 2, 3, 4, 5],\n",
    "    'status': ['canceled', 'cancelled', 'cancelled', 'cancelled', 'cancelled'],\n",
    "    'join_date': ['2016-10-02', '2016-12-21', '2016-12-22', '2016-12-23','2016-12-23'],\n",
    "    'days_to_cancel': [10, 12, 13, 14, 15]\n",
    "}, index=[\n",
    "    'First', 'Second', 'Third', 'Fourth', 'Fifth'\n",
    "])\n",
    "\n",
    "print(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Accessing Data\n",
    "\n",
    "Data in a data frame can be accessed using position based integer values or index based associative values (similar to Pandas Series) using iloc and loc respectively\n",
    "\n",
    "Take a look at the examples below to get an idea.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R003</th>\n",
       "      <th>R004</th>\n",
       "      <th>R005</th>\n",
       "      <th>R006</th>\n",
       "      <th>R007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05-01-11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-02-11</th>\n",
       "      <td>1478</td>\n",
       "      <td>3877</td>\n",
       "      <td>3674</td>\n",
       "      <td>2328</td>\n",
       "      <td>2539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-03-11</th>\n",
       "      <td>1613</td>\n",
       "      <td>4088</td>\n",
       "      <td>3991</td>\n",
       "      <td>6461</td>\n",
       "      <td>2691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-04-11</th>\n",
       "      <td>1560</td>\n",
       "      <td>3392</td>\n",
       "      <td>3826</td>\n",
       "      <td>4787</td>\n",
       "      <td>2613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-05-11</th>\n",
       "      <td>1608</td>\n",
       "      <td>4802</td>\n",
       "      <td>3932</td>\n",
       "      <td>4477</td>\n",
       "      <td>2705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-06-11</th>\n",
       "      <td>1576</td>\n",
       "      <td>3933</td>\n",
       "      <td>3909</td>\n",
       "      <td>4979</td>\n",
       "      <td>2685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-07-11</th>\n",
       "      <td>95</td>\n",
       "      <td>229</td>\n",
       "      <td>255</td>\n",
       "      <td>496</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-08-11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-09-11</th>\n",
       "      <td>1438</td>\n",
       "      <td>3785</td>\n",
       "      <td>3589</td>\n",
       "      <td>4174</td>\n",
       "      <td>2215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05-10-11</th>\n",
       "      <td>1342</td>\n",
       "      <td>4043</td>\n",
       "      <td>4009</td>\n",
       "      <td>4665</td>\n",
       "      <td>3033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          R003  R004  R005  R006  R007\n",
       "05-01-11     0     0     2     5     0\n",
       "05-02-11  1478  3877  3674  2328  2539\n",
       "05-03-11  1613  4088  3991  6461  2691\n",
       "05-04-11  1560  3392  3826  4787  2613\n",
       "05-05-11  1608  4802  3932  4477  2705\n",
       "05-06-11  1576  3933  3909  4979  2685\n",
       "05-07-11    95   229   255   496   201\n",
       "05-08-11     2     0     1    27     0\n",
       "05-09-11  1438  3785  3589  4174  2215\n",
       "05-10-11  1342  4043  4009  4665  3033"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=ridership,\n",
    "                    index=['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "                           '05-06-11', '05-07-11', '05-08-11', '05-09-11', '05-10-11'],\n",
    "                    columns=['R003', 'R004', 'R005', 'R006', 'R007']\n",
    "                    )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R003    0\n",
      "R004    0\n",
      "R005    2\n",
      "R006    5\n",
      "R007    0\n",
      "Name: 05-01-11, dtype: int64\n",
      "R003    1560\n",
      "R004    3392\n",
      "R005    3826\n",
      "R006    4787\n",
      "R007    2613\n",
      "Name: 05-04-11, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Accessing rows\n",
    "if True:\n",
    "    print(data.iloc[0])  # Position Based\n",
    "    print(data.loc['05-04-11'])  # Index Based\n",
    "\n",
    "# Accessing multiple rows\n",
    "if False:\n",
    "    print(data.iloc[1:4])\n",
    "\n",
    "# Accessing individual elements\n",
    "if False:\n",
    "    print(data.iloc[0, 3])  # Position Based (row, col)\n",
    "    print(data.loc['05-05-11', 'R006'])  # Index and column name based (row, col)\n",
    "\n",
    "# Accessing individual columns using column names\n",
    "if False:\n",
    "    print(data['R005'])\n",
    "\n",
    "# Accessing multiple columns\n",
    "if False:\n",
    "    print(data[[0, 3]])\n",
    "    print(data[['R005', 'R004']])\n",
    "\n",
    "# Accessing values in the dataframe\n",
    "if False:\n",
    "    print(data.values)  # Returns a 2D Numpy Array\n",
    "\n",
    "# Pandas Axis\n",
    "if False:\n",
    "    print(data.sum())  # Math aggregation operations work column-wise by default\n",
    "    print(data.sum(axis=1))  # To switch them to row-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Do the same exercise to calculate the mean ridership for the station with the most riders on the first day and the overall mean, but this time using dataframes instead of pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def mean_riders_for_max_station(ridership):\n",
    "    '''\n",
    "    Fill in this function to find the station with the maximum riders on the\n",
    "    first day, then return the mean riders per day for that station. \n",
    "    Use argmax() on the row to get the name of the column that has the maximum value in that row.\n",
    "    Also return the mean ridership overall for comparision.\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "mean_riders_for_max_station(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reading in Data into a DataFrame\n",
    "\n",
    "A DataFrame, being 2-Dimensional data structure is very suitable to load data from .csv or excel files. You would use the `read_csv` function to load in data into the DataFrame. Once read, there are a lot of convenient methods you can call on the returned Pandas DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_engagement = pd.read_csv('../../resources/daily_engagement.csv')\n",
    "\n",
    "# View the read in values for the first 10 rows\n",
    "daily_engagement.head(10)\n",
    "\n",
    "# Get the values in the acct column\n",
    "daily_engagement['acct']\n",
    "\n",
    "# Get the number of unique values of acct\n",
    "len(daily_engagement['acct'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate the correlation between two data sets using the Pearson R measure of linear correlation. This should be done in the following steps.\n",
    "\n",
    " 1. For each data set, standardize the data by first calculating distance of each data point from the mean in multiples of the standard deviation. `(value - mean) / std_dev`\n",
    " 2. Mulitply the two standardized data sets and take the average of this product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in data set using the read_csv.\n",
    "subway_df = pd.read_csv(\"../../resources/nyc_subway_weather.csv\")\n",
    "\n",
    "\n",
    "def get_data_in_std_units(data):\n",
    "    pass\n",
    "\n",
    "\n",
    "def correlation(x, y):\n",
    "    \"\"\"\n",
    "    Fill in this function to compute the correlation between the two\n",
    "    input variables. Each input is either a NumPy array or a Pandas\n",
    "    Series.\n",
    "\n",
    "    correlation = average of (x in standard units) times (y in standard units)\n",
    "\n",
    "    Remember to pass the argument \"ddof=0\" to the Pandas std() function!\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "rain = subway_df['meanprecipi']\n",
    "temp = subway_df['meantempi']\n",
    "\n",
    "correlation(rain, temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Vectorized operations\n",
    "\n",
    "Vectorized operations in DataFrames work similar to those in Numpy Arrays, except that elements are matched up by index and column-name rather than by position. Examples of these are provided in the code snippet below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Adding DataFrames with the column names\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]})\n",
    "    print(df1 + df2)\n",
    "    \n",
    "# Adding DataFrames with overlapping column names \n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6], 'c': [7, 8, 9]})\n",
    "    df2 = pd.DataFrame({'d': [10, 20, 30], 'c': [40, 50, 60], 'b': [70, 80, 90]})\n",
    "    print(df1 + df2)\n",
    "\n",
    "# Adding DataFrames with overlapping row indexes\n",
    "if False:\n",
    "    df1 = pd.DataFrame({'a': [1, 2, 3], 'd': [4, 5, 6], 'c': [7, 8, 9]},\n",
    "                       index=['row1', 'row2', 'row3'])\n",
    "    df2 = pd.DataFrame({'a': [10, 20, 30], 'b': [40, 50, 60], 'c': [70, 80, 90]},\n",
    "                       index=['row4', 'row3', 'row2'])\n",
    "    print(df1 + df2)\n",
    "    \n",
    "# Adding a Series to a DataFrame\n",
    "if False:\n",
    "    df1 = pd.DataFrame({\n",
    "        0: [1, 2, 3],\n",
    "        1: [4, 5, 6],\n",
    "        2: [7, 8, 9]\n",
    "    })\n",
    "    series = pd.Series([101, 102, 103])\n",
    "    \n",
    "    print(df1)\n",
    "    print(series)\n",
    "\n",
    "    # Adds the elements of the series \"column-wise\" to get the result.\n",
    "    print(df1 + series)\n",
    "\n",
    "    # Adds it index-wise (row-wise)\n",
    "    print(df1.add(series, axis=\"index\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Given a dataframe that contains cumulative information on a bank balance per month, write a function that would return a data frame that displays the monthly incremental amount added to the account.\n",
    "\n",
    "*Hint: Use the shift() function on a DataFrame to get to the previous row*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bank_balance = pd.DataFrame({\n",
    "    'account_1': [3144312, 3144335, 3144353, 3144424, 3144594, 3144808,\n",
    "                  3144895, 3144905, 3144941, 3145094, 3147483, 3148473],\n",
    "    'account_2': [1088151, 1088159, 1088177, 1088231, 1088275, 1088317,\n",
    "                  1088328, 1088331, 1088420, 1088753, 1093827, 1098573]\n",
    "}, index=[\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"])\n",
    "\n",
    "\n",
    "def get_monthly_balance(balance):\n",
    "    '''\n",
    "    Fill in this function to take a DataFrame with cumulative entries\n",
    "    and exits (entries in the first column, exits in the second) and\n",
    "    return a DataFrame with monthly entries and exits (entries in the\n",
    "    first column, exits in the second).\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "get_monthly_balance(bank_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Run the standardize operation on a set of exam scores. The scores need to be standardized by exam as well as by student.\n",
    "\n",
    "*Note: This is the same standardization operation shown earlier where you need to subtract each score from the mean and divide by its standard deviation. To get the student-wise result though you will need to standardize by row*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grades_df = pd.DataFrame(\n",
    "    data={'exam1': [43, 81, 78, 75, 89, 70, 91, 65, 98, 87],\n",
    "          'exam2': [24, 63, 56, 56, 67, 51, 79, 46, 72, 60]},\n",
    "    index=['Andre', 'Barry', 'Chris', 'Dan', 'Emilio', \n",
    "           'Fred', 'Greta', 'Humbert', 'Ivan', 'James']\n",
    ")\n",
    "\n",
    "\n",
    "def standardize(df):\n",
    "    \"\"\"\n",
    "    Try to use vectorized operations.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def standardize_rows(df):\n",
    "    \"\"\"\n",
    "    This one is more challenging than standardizing each column. \n",
    "    Hint: You'll need to use the axis argument in the vector operations.\n",
    "    \"\"\"\n",
    "    pass\n",
    "    \n",
    "standardize_rows(grades_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The way to remember the application of the index functions, is to think of it as a way to determine how to get the individual elements to perform the operation.\n",
    "\n",
    " * Math Reduce operations (sum, mean, etc): The axis will specify the dimension along which to obtain the individual elements over which to run the reduce op. So for mean with `axis=\"index\"` you specify to get the component elements from each index and return a mean for the numbers of each index in a column --- The returns a column-wise mean. For `axis=\"columns\"` you specify to get the elements from each column and return the row-wise mean. *This is admittedly counter-intuitive*\n",
    " * Two-Arg Vector operations (add, subtract, divide): The axis here will specify the dimension along which to match up elements for the operation. So `df1.add(series, axis=\"index\")` specifies to match up elements of the series index-wise to the dataframe and perform a row-wise addition. `df1.add(series, axis=\"columns\")` would mean to transpose the Series into a row and match up the elements column-wise to perform a column-wise addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Custom functions\n",
    "\n",
    "As with Series, you can run custom functions over elements of a DataFrame using the `apply` function. However there are differences in how apply works with Series and DataFrames that you need to be aware of.\n",
    "\n",
    "#### apply\n",
    "Recall that with Series, `apply` works by running a custom function over individual elements of the Series. DataFrames, though are collections of Series, where `each element` of a DataFrame represents an entire Series (column). Therefore, the `apply` function runs the custom function over each entire Series, as opposed to each individual element within each Series. The apply function does take in an `axis` parameter, which specifies whether to run the custom function column-wise or row-wise. \n",
    "\n",
    "Note that apply can also be used to implement a `reduce` operation: Where the provided function takes in a Series and returns a single numerical value: eg. mean(), max(). Using such a function on a 2-D DataFrame will convert it down to a 1-D Series\n",
    "\n",
    "#### applymap\n",
    "In order to run a custom function over each individual element in each Series within a DataFrame, use the `applyMap` function instead\n",
    "\n",
    "Take a look at the examples below to see each case in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a   b   c\n",
      "0  2  11   6\n",
      "1  3  21  11\n",
      "2  4  31  16\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'a': [1, 2, 3],\n",
    "    'b': [10, 20, 30],\n",
    "    'c': [5, 10, 15]\n",
    "})\n",
    "\n",
    "# DataFrame apply\n",
    "if False:\n",
    "    def get_mean(series):\n",
    "        return series.mean()\n",
    "    \n",
    "    def square(series):\n",
    "        return series ** 2\n",
    "    \n",
    "    # Column-wise (Series-wise) application of apply: Default\n",
    "    print(df.apply(square))\n",
    "    \n",
    "    # Row-wise apply\n",
    "    print(df.apply(square, axis=1))\n",
    "\n",
    "    # Use of apply for a reduce operation\n",
    "    print(df.apply(get_mean))\n",
    "\n",
    "# DataFrame applymap()\n",
    "if True:\n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "        \n",
    "    print(df.applymap(add_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Group Operations\n",
    "\n",
    "Grouping and aggregating data is possible using the groupby call on a DataFrame object. Running groupby will return you a special type of object of type `DataFrameGroupBy` on which you can run further operations.\n",
    " * Think of the DataFrameGroupBy object as a dictionary matching the elements that your grouping on with a separate DataFrame containing only the group of rows that match that group key\n",
    " * Once you have your data grouped by keys in a `DataFrameGroupBy` object, you can then run aggregation functions on each group to get the grouped information you need (see example below)\n",
    " * `DataFrameGroupBy` provides a bunch of convenient functions that you can use to run over the groups of data. If you want to run additional custom functions, you can use `apply` as you did with dataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "even\n",
      "False     5\n",
      "True     16\n",
      "Name: value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "values = np.array([1, 3, 2, 4, 1, 6, 4])\n",
    "example_df = pd.DataFrame({\n",
    "    'value': values,\n",
    "    'even': values % 2 == 0,\n",
    "    'above_three': values > 3 \n",
    "}, index=['a', 'b', 'c', 'd', 'e', 'f', 'g'])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Examine DataFrame\n",
    "if False:\n",
    "    print(example_df)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Examine groups\n",
    "if True:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    # The groups attribute is a dictionary mapping keys to lists of row indexes\n",
    "    print(grouped_data.groups)\n",
    "    print(grouped_data.sum()[\"value\"])\n",
    "    \n",
    "# Group by multiple columns\n",
    "if False:\n",
    "    grouped_data = example_df.groupby(['even', 'above_three'])\n",
    "    print(grouped_data.groups)\n",
    "    \n",
    "# Get sum of each group\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    print(grouped_data.sum())\n",
    "    \n",
    "# Limit columns in result\n",
    "if False:\n",
    "    grouped_data = example_df.groupby('even')\n",
    "    \n",
    "    # You can take one or more columns from the result DataFrame\n",
    "    print(grouped_data.sum()['value'])\n",
    "    \n",
    "    print('\\n')     # Blank line to separate results)\n",
    "    \n",
    "    # You can also take a subset of columns from the grouped data before \n",
    "    # collapsing to a DataFrame. In this case, the result is the same.\n",
    "    print(grouped_data['value'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Read in the data about subway ridership and group it by a variable of your choice. Then find the mean ridership for each value and provide a plot of the mean of this group data once you are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subway_df = pd.read_csv(\"../../resources/nyc_subway_weather.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Joining DataFrames\n",
    "\n",
    "DataFrames support operations that enable you to perform SQL-like joins on them. An example of this could be if you have multiple DataFrames that have related data and you want to combine them to produce some consolidated output key-ed on one of the fields --- Much like an SQL Join. To do this you would use the `merge` operation like so\n",
    "\n",
    "```python\n",
    "dataFrame1.merge(dataFrame2, on=\"account\", how=\"inner\")\n",
    "```\n",
    "\n",
    "This code will perform an inner join of dataFrame1 on dataFrame2 on the `account` column, producing a dataframe with the combined output *Like an inner join*. Setting how to `left`, `right` or `outer` will return a dataframe with an outer join done on the data. If you need to perform a join on multiple columns, you should provide an array of arguments to the `on` parameter.\n",
    "\n",
    "If the columns you want to join on, are named differently in the two dataframes, you would use the `right_on` and `left_on` arguments to the merge call, instead of the single `on` parameter.\n",
    "\n",
    "#### Exercise\n",
    "Given two dataframes: One that contains ridership information and the other that contains weather info, write a function that joins the two dataframes that produces ridership and weather information for each date and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "subway_df = pd.DataFrame({\n",
    "    'UNIT': ['R003', 'R003', 'R003', 'R003', 'R003', 'R004', 'R004', 'R004',\n",
    "             'R004', 'R004'],\n",
    "    'DATEn': ['05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11',\n",
    "              '05-01-11', '05-02-11', '05-03-11', '05-04-11', '05-05-11'],\n",
    "    'ENTRIESn': [ 4388333,  4388348,  4389885,  4391507,  4393043, 14656120,\n",
    "                 14656174, 14660126, 14664247, 14668301],\n",
    "    'EXITSn': [ 2911002,  2911036,  2912127,  2913223,  2914284, 14451774,\n",
    "               14451851, 14454734, 14457780, 14460818],\n",
    "    'latitude': [ 40.689945,  40.689945,  40.689945,  40.689945,  40.689945,\n",
    "                  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.872564, -73.872564, -73.872564, -73.872564,\n",
    "                  -73.867135, -73.867135, -73.867135, -73.867135, -73.867135]\n",
    "})\n",
    "\n",
    "weather_df = pd.DataFrame({\n",
    "    'DATEn': ['05-01-11', '05-01-11', '05-02-11', '05-02-11', '05-03-11',\n",
    "              '05-03-11', '05-04-11', '05-04-11', '05-05-11', '05-05-11'],\n",
    "    'latitude': [ 40.689945,  40.69132 ,  40.689945,  40.69132 ,  40.689945,\n",
    "                  40.69132 ,  40.689945,  40.69132 ,  40.689945,  40.69132 ],\n",
    "    'longitude': [-73.872564, -73.867135, -73.872564, -73.867135, -73.872564,\n",
    "                  -73.867135, -73.872564, -73.867135, -73.872564, -73.867135],\n",
    "    'pressurei': [ 30.24,  30.24,  30.32,  30.32,  30.14,  30.14,  29.98,  29.98,\n",
    "                   30.01,  30.01],\n",
    "    'fog': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'rain': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    'tempi': [ 52. ,  52. ,  48.9,  48.9,  54. ,  54. ,  57.2,  57.2,  48.9,  48.9],\n",
    "    'wspdi': [  8.1,   8.1,   6.9,   6.9,   3.5,   3.5,  15. ,  15. ,  15. ,  15. ]\n",
    "})\n",
    "\n",
    "def combine_dfs(subway_df, weather_df):\n",
    "    '''\n",
    "    Fill in this function to take 2 DataFrames, one with subway data and one with weather data,\n",
    "    and return a single dataframe with one row for each date, hour, and location. Only include\n",
    "    times and locations that have both subway data and weather data available.\n",
    "    '''\n",
    "    \n",
    "    pass\n",
    "    \n",
    "results = combine_dfs(subway_df, weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Plotting Data\n",
    "As with Series, DataFrame objects provide a `plot` function that help you plot data within the DataFrame. If you have multiple columns in a DataFrame, calling the plot function will produce a line plot with each Series represented as a different color.\n",
    "\n",
    "The `plot` function produces a line plot as a default. To produce other kinds of plot, you should set the value of the `kind` parameter to the appropriate values (`pie`, `scatter`, etc.)\n",
    "\n",
    "#### Exercise\n",
    "Use the subway ridership DataFrame to create one of the following plot\n",
    "\n",
    " * A scatter plot of latitude on the x axis and longitude on the y-axis and ridership as the bubble size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "subway_df = pd.read_csv(\"../../resources/nyc_subway_weather.csv\")\n",
    "\n",
    "data_by_location = subway_df.groupby(['latitude', 'longitude'], as_index=False).mean()\n",
    "\n",
    "# subway_df.groupby('DATEn')['ENTRIESn_hourly'].head(100).hist()\n",
    "\n",
    "scaled_entries = data_by_location['ENTRIESn_hourly'] / data_by_location['ENTRIESn_hourly'].std()\n",
    "plt.scatter(data_by_location['latitude'], data_by_location['longitude'], s=scaled_entries*10)\n",
    "\n",
    "# data_by_location.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
